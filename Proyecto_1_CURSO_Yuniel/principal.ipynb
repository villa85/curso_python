{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Nivel I\n",
    "\n",
    "**Nombre del Alumno: Yuniel Antonio Villalón Rosales**\n",
    "\n",
    "## Parte 1: Normalización de un texto\n",
    "\n",
    "### Pasos:\n",
    "\n",
    "1.  Leer el archivo texto (ver código anexo)\n",
    "2.  Contar cuantas palabras tiene el texto antes de preprocesarlo\n",
    "3.  Convertir el texto Normalizado a minúsculas\n",
    "4.  Identificar, mostrar y eliminar signos de puntuación\n",
    "5.  Identificar, mostrar y eliminar las letras acentuadas sustituirlas por la misma letra sin acento\n",
    "6.  Identificar, mostrar y eliminar los números\n",
    "7.  Identificar y mostrar  todas las palabras que comience en Mayúscula\n",
    "8.  Identificar y mostrar todas las siglas encontradas en el texto, por ejemplo: SIDA, VIH, OMS, IAVI, GSK, etc.\n",
    "9.  Eliminar todas las palabras “stop words”1 del texto.  Se suministrar un archivo texto\n",
    "“stopwords_español.txt” con el listado de palabras en español.\n",
    "10. Contar cuantas veces aparece cada una de las palabras que quedan en el texto una vez\n",
    "realizada la normalización.\n",
    "11. Incluir el control de excepciones en los procesos donde abrimos los archivos de texto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Variables y Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables globales y constantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Módulos y Funciones\n",
    "\n",
    "Importar los módulos y las funciones deben estar en un fichero **mis_funciones.py** y desde aqui debemos importarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funtions import mis_funciones as mf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Leer el archivo texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ruta_file = 'articulo.txt'\n",
    "    archivo = open(\"datos\\\\\"+ruta_file, encoding=\"utf8\") # EJCERCICIO 11 CONTROL DE EXCEPCIONES\n",
    "    articulo = archivo.read()\n",
    "    archivo.close()\n",
    "except IOError as error:\n",
    "    print('Problema con el fichero: {}.  {}'.format(ruta_file, error) )\n",
    "except:  # si es un error diferente a IOError\n",
    "    print(\"Error inesperado:\", sys.exc_info()[0])\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Contar cuantas palabras tiene el texto antes de preprocesarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_palablas_antes = len(mf.split_cadena(articulo))\n",
    "print(f\"La cantidad de palabras antes de ser procesado es de {cantidad_palablas_antes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Convertir el texto Normalizado a minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo_minusculas = mf.texto_en_minusculas(articulo)\n",
    "print(todo_minusculas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Identificar, mostrar y eliminar signos de puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_no_signos = mf.elimina_signos_puntuacion(todo_minusculas)\n",
    "solo_signos = mf.elimina_signos_puntuacion(todo_minusculas, signos = True)\n",
    "print(f\"Los signos de puntuación encontrados: \\n{solo_signos} \\n\")\n",
    "print(f\"Texto sin signos de puntuación: \\n {texto_no_signos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Identificar, mostrar y eliminar las letras acentuadas sustituirlas por la misma letra sin acento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letras_acentuadas = mf.letras_acentuadas(texto_no_signos , find = True)\n",
    "texto_sin_letras_acentuadas = mf.letras_acentuadas(texto_no_signos)\n",
    "print(f\"{letras_acentuadas}\", end= \" \\n \\n \")\n",
    "print(f\"{texto_sin_letras_acentuadas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6: Identificar, mostrar y eliminar los números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeros = mf.extrae_numeros(texto_sin_letras_acentuadas, number = True)\n",
    "texto_sin_numeros = mf.extrae_numeros(texto_sin_letras_acentuadas)\n",
    "print(numeros, end= \" \\n \\n \")\n",
    "print(f\"{texto_sin_numeros}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 7: Identificar y mostrar  todas las palabras que comience en Mayúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_mayusculas = mf.extrae_mayusculas(articulo)\n",
    "print(palabras_mayusculas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 8: Identificar y mostrar todas las siglas encontradas en el texto, por ejemplo: SIDA, VIH, OMS, IAVI, GSK, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siglas = mf.extrae_mayusculas(articulo, siglas= True)\n",
    "print(siglas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 9: Eliminar todas las palabras “stop words”1 del texto.  Se suministrar un archivo texto“stopwords_español.txt” con el listado de palabras en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    r_file = 'stopwords_español.txt'\n",
    "    file = open(\"datos\\\\\"+r_file, encoding=\"utf8\") # PASO 11 CONTROL DE EXCEPCIONES \n",
    "    stop_words = file.read()\n",
    "    file.close()\n",
    "except IOError as error:\n",
    "    print('Problema con el fichero: {}.  {}'.format(r_file, error) )\n",
    "except:  # si es un error diferente a IOError\n",
    "    print(\"Error inesperado:\", sys.exc_info()[0])\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_sin_tildes_stop_words = mf.letras_acentuadas(stop_words) # quita las tildes del las stop_words\n",
    "texto_filtrado_no_stop_words = mf.elimina_stop_words(texto_sin_numeros, texto_sin_tildes_stop_words) # devuelve el texto filtrado sin stop words\n",
    "cantidad_palablas = len(mf.split_cadena(texto_filtrado_no_stop_words))\n",
    "print(texto_filtrado_no_stop_words, end='\\n\\n')\n",
    "print(f\"La cantidad de palabras despues de ser procesado es de {cantidad_palablas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 10: Contar cuantas veces aparece cada una de las palabras que quedan en el texto una vez realizada la normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_x_palabra = mf.contar_palabras(texto_filtrado_no_stop_words)\n",
    "print(cantidad_x_palabra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 11: Incluir el control de excepciones en los procesos donde abrimos los archivos de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las excepciones fueron incluidas en paso 1 y el paso 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Sentimientos\n",
    "\n",
    "### Paso 1: Cree una función que reciba como parámetro un texto y retorne el mismo texto en minúscula\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    s_weets_file = 'sentweets_esp.txt'\n",
    "    file_s = open(\"datos\\\\\"+s_weets_file, encoding=\"utf8\") # PASO 11 CONTROL DE EXCEPCIONES \n",
    "    sentweets = file_s.read(10000)\n",
    "    file_s.close()\n",
    "except IOError as error:\n",
    "    print('Problema con el fichero: {}.  {}'.format(file_s, error) )\n",
    "except:  # si es un error diferente a IOError\n",
    "    print(\"Error inesperado:\", sys.exc_info()[0])\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txt_minusculas = mf.texto_en_minusculas(sentweets)\n",
    "print(txt_minusculas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Crear una función que reciba como parámetro un texto y retorne el texto sin las urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texto_sin_url = mf.extraer_url(txt_minusculas)\n",
    "print(texto_sin_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Crear una función que reciba como parámetro un texto y retorne el texto sin las menciones a usuarios @usuarioabc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texto_sin_usuarios = mf.extraer_usuarios(texto_sin_url)\n",
    "print(texto_sin_usuarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Crear una o más funciones reciba como parámetro un texto, retorne los signos de puntuación encontrados en el texto y retorne el texto sin los signos de puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texto_sin_signos = mf.elimina_signos_puntuacion(texto_sin_usuarios)\n",
    "signos = mf.elimina_repetidos(mf.elimina_signos_puntuacion(texto_sin_usuarios, signos = True))\n",
    "print(signos, end= \" \\n \\n \")\n",
    "print(texto_sin_signos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Crear una función que reciba como parámetros un texto, retorne las letras con acento que encontró en el texto y retorne un nuevo texto (donde sustituya la letra acentuada por la misma letra sin acento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letras_acent_sentweets = mf.letras_acentuadas(texto_sin_signos , find = True)\n",
    "texto_sin_letras_acent_sentweets = mf.letras_acentuadas(texto_sin_signos)\n",
    "print(letras_acent_sentweets, end= \" \\n \\n \")\n",
    "print(texto_sin_letras_acent_sentweets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6: Crear una función que recibe como parámetro un archivo texto, retorne los números encontrados en el texto y retorne el texto sin números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeros_s = mf.extrae_numeros(texto_sin_letras_acent_sentweets, number = True)\n",
    "texto_s_sin_numeros = mf.extrae_numeros(texto_sin_letras_acent_sentweets)\n",
    "\n",
    "print(numeros_s, end= \" \\n \\n \")\n",
    "print(texto_s_sin_numeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 7: Crear una función que reciba como parámetro un texto y retorne las palabras que comience en mayúscula encontradas en el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_mayus_sent = mf.extrae_mayusculas(sentweets)\n",
    "print(palabras_mayus_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 8: Crear una función que reciba como parámetro un texto y retorne las siglas encontradas en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siglas_s = mf.extrae_mayusculas(sentweets, siglas= True)\n",
    "print(siglas_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 9: Crear una función que reciba como parámetro un texto, muestre las palabras “stop words” encontradas y retorne un nuevo archivo sin las palabras “stop words”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_sin_tildes_stop_words = mf.letras_acentuadas(stop_words)\n",
    "texto_sentweets_filtrado_no_stop_words = mf.elimina_stop_words(texto_s_sin_numeros, texto_sin_tildes_stop_words)\n",
    "stop_word_encontradas = mf.elimina_stop_words(texto_s_sin_numeros, texto_sin_tildes_stop_words, stw = True)\n",
    "print(stop_word_encontradas, end= \" \\n \\n \")\n",
    "print(texto_sentweets_filtrado_no_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 10: Crear una función que reciba como parámetro un texto, lo divida en palabras y cuente cuantas veces aparece las palabras que quedan en el texto una vez “normalizado”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_conteo_palabras = mf.contar_palabras(texto_sentweets_filtrado_no_stop_words)\n",
    "print(lista_conteo_palabras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 11: Cree una función que calcule la puntuación total de palabras positivas y negativas encontradas en el texto. La puntuación de cada palabra aparece a la derecha en los archivos positive_lex.txt y negative_lex.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    negative_file = 'negative_lex.txt'\n",
    "    negative_s = open(\"datos\\\\\"+negative_file, encoding=\"utf8\") # PASO 11 CONTROL DE EXCEPCIONES\n",
    "    negative = negative_s.read()\n",
    "    negative_s.close()\n",
    "except IOError as error:\n",
    "    print('Problema con el fichero: {}.  {}'.format(negative_s, error) )\n",
    "except:  # si es un error diferente a IOError\n",
    "    print(\"Error inesperado:\", sys.exc_info()[0])\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    positive_file = 'positive_lex.txt'\n",
    "    positive_s = open(\"datos\\\\\"+positive_file, encoding=\"utf8\") # PASO 11 CONTROL DE EXCEPCIONES\n",
    "    positive = positive_s.read()\n",
    "    positive_s.close()\n",
    "except IOError as error:\n",
    "    print('Problema con el fichero: {}.  {}'.format(positive_s, error) )\n",
    "except:  # si es un error diferente a IOError\n",
    "    print(\"Error inesperado:\", sys.exc_info()[0])\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sin_acentos = mf.letras_acentuadas(positive)\n",
    "negative_sin_acentos = mf.letras_acentuadas(negative)\n",
    "lista_negativas = mf.normaliza(negative_sin_acentos)\n",
    "lista_positivas = mf.normaliza(positive_sin_acentos)\n",
    "\n",
    "lista_total_positivas = mf.calculo_puntuacion_palabras(lista_positivas, lista_conteo_palabras)\n",
    "lista_total_negativas = mf.calculo_puntuacion_palabras(lista_negativas, lista_conteo_palabras)\n",
    "total_puntos_positivos = mf.total_puntuacion(lista_total_positivas)\n",
    "total_puntos_negativos = mf.total_puntuacion(lista_total_negativas)\n",
    "print(lista_total_positivas, end= \" \\n \\n \")\n",
    "print(lista_total_negativas, end= \" \\n \\n \")\n",
    "print(f\"El total de puntos positivos del texto es {total_puntos_positivos} y de negativos {total_puntos_negativos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "Durante la ejecución del proyecto he encontrado dificultades en procesamiento de datos, pues en un principio interpretaba los String como “listas” haciendo muchos ciclos for, lo que hacía menos eficiente el código, ocasionando que los tiempos de análisis fueran elevados, hasta que con la utilización de expresiones regulares, logre optimizar en gran medida las funciones. No logre conseguir mejorar las funciones de contar palabras, ni la del cálculo de valores de sentimiento, llevando estas ultimas un tiempo alto de gestión de datos. Por eso he acotado el “scope” del read() a 10000 caracteres. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecciones\n",
    "\n",
    "Las lecciones que he aprendido en el transcurso del proyecto es que el tiempo de ejecución es vital, por lo que siempre se debe elegir los métodos más eficientes para que la realización de una tarea, y que esta no tome más de lo necesario pues la tardanza se “traduce” en gastos de recursos y dinero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1353f313ead104360866fab643a74fd0c61057d61236ce27455bd3419eefba5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
